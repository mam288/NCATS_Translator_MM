{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64020f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c5429b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Import AOP EC table data\n",
    "# AOP_EC_table = pd.read_csv(\"../aop_ke_ec.csv\")\n",
    "AOP_EC_table = pd.read_csv(\"../../aop_wiki_tables/aop_ke_ec.csv\")\n",
    "AOP_KE_table = pd.read_csv(\"../../aop_wiki_tables/aop_ke_mie_ao.tsv\", sep=\"\\t\")\n",
    "AOP_KER_table = pd.read_csv(\"../../aop_wiki_tables/aop_ke_ker.tsv\", sep=\"\\t\")\n",
    "# AOP_KE_table = pd.read_csv(\"../aop_ke_mie_ao.tsv\", sep=\"\\t\")\n",
    "# AOP_KER_table = pd.read_csv(\"../aop_ke_ker.tsv\", sep=\"\\t\")\n",
    "\n",
    "AOP_num = 6\n",
    "\n",
    "#Set output file name\n",
    "outfile = f\"../aop{AOP_num}_from_script.ttl\"\n",
    "print(AOP_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a930ca09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "AOP_EC = pd.DataFrame()\n",
    "AOP_EC = AOP_EC_table[AOP_EC_table[\"AOP\"] == f\"Aop:{AOP_num}\"]\n",
    "AOP_EC[\"KE\"] = [int(re.sub(\"Event\\:\", \"\", x)) for x in AOP_EC[\"Key Event\"]]\n",
    "\n",
    "AOP_KE = pd.DataFrame()\n",
    "AOP_KE = AOP_KE_table[AOP_KE_table[\"AOP\"] == f\"Aop:{AOP_num}\"]\n",
    "AOP_KE[\"KE\"] = [int(re.sub(\"Event\\:\", \"\", x)) for x in AOP_KE[\"Key Event\"]]\n",
    "AO_dict = {}\n",
    "for index, row in AOP_KE.iterrows():\n",
    "    AO_dict[row.KE] = re.sub(\",\", \";\", row[\"Adverse Outcome\"])\n",
    "\n",
    "AOP_KER = pd.DataFrame()\n",
    "AOP_KER = AOP_KER_table[AOP_KER_table[\"AOP\"] == f\"Aop:{AOP_num}\"]\n",
    "AOP_KER[\"Event1\"] = [int(re.sub(\"Event\\:\", \"\", x)) for x in AOP_KER[\"Event1\"]]\n",
    "AOP_KER[\"Event2\"] = [int(re.sub(\"Event\\:\", \"\", x)) for x in AOP_KER[\"Event2\"]]\n",
    "\n",
    "\n",
    "KE_pairs = []\n",
    "for index, row in AOP_KER.iterrows():\n",
    "    # if row.adjacent == \"adjacent\":\n",
    "    KE_pairs += [(row.Event1, row.Event2)]\n",
    "\n",
    "print (KE_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd77448",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# write header \n",
    "header = '''@prefix : <http://www.semanticweb.org/mmandal/ontologies/2022/4/untitled-ontology-76#> .\n",
    "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix xml: <http://www.w3.org/XML/1998/namespace> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@base <http://www.w3.org/2002/07/owl#> .\n",
    "\n",
    "[ rdf:type owl:Ontology ;\n",
    "   owl:imports <http://purl.obolibrary.org/obo/go/releases/2022-01-13/go.owl> ,\n",
    "               <http://purl.obolibrary.org/obo/ro/releases/2022-01-20/ro.owl>\n",
    " ] .\n",
    "'''\n",
    "\n",
    "with open(outfile, \"w+\") as f:\n",
    "    f.write(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca68808",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_term(input_id, name):\n",
    "    \"\"\"\n",
    "    Takes a term and id and returns ttl class and instance statements\n",
    "    \"\"\"\n",
    "    if \":\" in input_id:\n",
    "        input_id_str = f\"{input_id[:2]}_{input_id[3:]}\"\n",
    "    else:\n",
    "        input_id_str = input_id\n",
    "    name = re.sub(\" \", \"_\", name)\n",
    "    class_statement = f'''\\n###  http://purl.obolibrary.org/obo/{input_id_str}\\n\\t<http://purl.obolibrary.org/obo/{input_id_str}> rdf:type owl:Class .\\n\\n'''\n",
    "    instance_statement = f'''###  http://www.co-ode.org/ontologies/ont.owl#{name}\\n<http://www.co-ode.org/ontologies/ont.owl#{name}> rdf:type owl:NamedIndividual ,\\n\\t<http://purl.obolibrary.org/obo/{input_id_str}> '''\n",
    "\n",
    "    return class_statement, instance_statement;\n",
    "\n",
    "def get_action_id (act,  source_1, id_1, term_1, source_2, id_2, term_2):\n",
    "#     if act == \"\": # step action\n",
    "#     else: # row action\n",
    "        \n",
    "    if act == \"increased\":\n",
    "        return \"RO_0000057\"\n",
    "    else:\n",
    "        return \"RO_0000058\"\n",
    "\n",
    "    \n",
    "\n",
    "def add_action(act, source_1, id_1, term_1, source_2, id_2, term_2, outfile):\n",
    "    action_id = get_action_id(act, source_1, id_1, term_1, source_2, id_2, term_2)\n",
    "    row = f\"{act},{action_id},{source_1},{id_1},{term_1},{source_2},{id_2},{term_2}\\n\"\n",
    "    # with open(outfile, \"a\") as f:\n",
    "    #         f.write(row)\n",
    "    # prepend_line(outfile, row)\n",
    "    if act != \"\":\n",
    "        action_statement = f\";\\n\\t<http://purl.obolibrary.org/obo/{action_id}> <http://www.co-ode.org/ontologies/ont.owl#{term_2}> \"\n",
    "        return(action_statement)\n",
    "    else:\n",
    "        return(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d413e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes = {}\n",
    "instances = {}\n",
    "steps = {}\n",
    "# Cycle through rows and create classes and instances\n",
    "outfile_csv = f\"../outfile_09122022_AOP{AOP_num}.csv\"\n",
    "KE_dict = {}\n",
    "\n",
    "\n",
    "for index, row in AOP_EC.iterrows():\n",
    "    row = row.rename(lambda x: re.sub(\"[\\s\\/]\", \"_\", x.lower()))\n",
    "\n",
    "\n",
    "    # if object_id is not already in classes.keys() add object_id\n",
    "    if row.object_id not in classes.keys() and not pd.isna(row.object_id):\n",
    "        class_statement, instance_statement = process_term(row.object_id, row.object_term)\n",
    "        classes[row.object_id] = class_statement\n",
    "        instances[row.object_id] = instance_statement\n",
    "        \n",
    "    # if process_phenotype_id is not already in instances.keys() add process_phenotype_id\n",
    "    if row.process_phenotype_id not in instances.keys() and not pd.isna(row.process_phenotype_id):\n",
    "        class_statement, instance_statement = process_term(row.process_phenotype_id, row.process_phenotype_term)\n",
    "        classes[row.process_phenotype_id] = class_statement\n",
    "        instances[row.process_phenotype_id] = instance_statement\n",
    "    \n",
    "    row_action_statement = add_action(row.action, row.object_source, row.object_id ,row.object_term, row.process_phenotype_source, row.process_phenotype_id,\n",
    "                                      row.process_phenotype_term, outfile_csv)\n",
    "\n",
    "    try:\n",
    "        KE_dict[row.ke] += [(row.action, row.object_source, row.object_id ,row.object_term, row.process_phenotype_source, row.process_phenotype_id, row.process_phenotype_term)]\n",
    "    except:\n",
    "        KE_dict[row.ke] = [(row.action, row.object_source, row.object_id ,row.object_term, row.process_phenotype_source, row.process_phenotype_id, row.process_phenotype_term)]\n",
    "    \n",
    "print(KE_dict)\n",
    "with open(outfile, \"a\") as f:\n",
    "            f.write(\"\\n\\n#################################################################\")     \n",
    "            f.write(\"\\n#   Classes\")  \n",
    "            f.write(\"\\n#################################################################\\n\\n\")  \n",
    "for c, s in classes.items():\n",
    "    with open(outfile, \"a\") as f:\n",
    "            f.write(s)\n",
    "with open(outfile, \"a\") as f:\n",
    "            f.write(\"\\n\\n#################################################################\")     \n",
    "            f.write(\"\\n#   Instances\")  \n",
    "            f.write(\"\\n#################################################################\\n\\n\")  \n",
    "for i, s in instances.items():\n",
    "    with open(outfile, \"a\") as f:\n",
    "            f.write(s + \".\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613e3d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(outfile_csv, \"w+\") as f:\n",
    "        f.write(f\"action,source_1,id_1,term_1,source_2,id_2,term_2,ke(s), adverse_outcome\\n\")\n",
    "\n",
    "prev_ke = \"\"\n",
    "for ke_1, ke_2 in KE_pairs:\n",
    "\n",
    "    for i, e in enumerate(KE_dict[ke_1]):\n",
    "        if ke_1 != prev_ke:\n",
    "            row = [x if not pd.isna(x) else \"\" for x in e]\n",
    "            row_str = ', '.join(row+[str(ke_1), AO_dict[ke_1]]) + '\\n'\n",
    "            with open(outfile_csv, \"a\") as f:\n",
    "                f.write(row_str)\n",
    "    for i2, e2 in enumerate(KE_dict[ke_2]):\n",
    "\n",
    "        row2 = [x if not pd.isna(x) else \"\" for x in e2]\n",
    "        row2_str = ', '.join(row2+[str(ke_2), AO_dict[ke_2]]) + '\\n'\n",
    "        row_between = [x if not pd.isna(x) else \"\" for x in row[4:] + row2[4:]]\n",
    "        row_between_str = ', '.join([\"\"] + row_between + [f\"{ke_1}_{ke_2}\", \"\"]) + '\\n'\n",
    "        with open(outfile_csv, \"a\") as f:\n",
    "            f.write(row_between_str)\n",
    "            f.write(row2_str)\n",
    "    prev_ke = ke_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b1713",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(AO_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f24e80",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}